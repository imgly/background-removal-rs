//! Build script for generating model configuration constants from model.json
//! Updated for rescale factor support

#![allow(missing_docs)]
#![allow(clippy::too_many_lines)]
#![allow(clippy::expect_used)]
#![allow(clippy::unwrap_used)]
#![allow(clippy::indexing_slicing)]
#![allow(clippy::panic)]
#![allow(clippy::format_push_string)]
#![allow(clippy::uninlined_format_args)]

use std::env;
use std::fs;
use std::path::Path;

fn main() {
    println!("cargo:rerun-if-changed=../../models");

    let out_dir = env::var("OUT_DIR").expect("OUT_DIR environment variable not set");
    let dest_path = Path::new(&out_dir).join("model_config.rs");

    // Get all embedded models based on features
    let embedded_models = get_embedded_models();

    if embedded_models.is_empty() {
        // No embedded models - generate empty registry
        let generated_code = r"
// Generated by build.rs - do not edit manually
// No embedded models configured

#[derive(Debug, Clone)]
pub struct EmbeddedModelData {
    pub name: String,
    pub model_data: Vec<u8>,
    pub input_name: String,
    pub output_name: String,
    pub input_shape: [usize; 4],
    pub output_shape: [usize; 4],
    pub preprocessing: PreprocessingConfig,
}

#[derive(Debug, Clone)]
pub struct PreprocessingConfig {
    pub target_size: [u32; 2],
    pub normalization_mean: [f32; 3],
    pub normalization_std: [f32; 3],
}

pub struct EmbeddedModelRegistry;

impl EmbeddedModelRegistry {
    #[must_use] pub fn get_model(_name: &str) -> Option<EmbeddedModelData> {
        None // No embedded models
    }
    
    #[must_use] pub fn list_available() -> &'static [&'static str] {
        &[] // Empty list
    }
}
";
        fs::write(&dest_path, generated_code).expect("Failed to write generated code");
        return;
    }

    // Generate model loader functions and registry
    let mut generated_code = String::from(
        r"
// Generated by build.rs - do not edit manually

#[derive(Debug, Clone)]
pub struct EmbeddedModelData {
    pub name: String,
    pub model_data: Vec<u8>,
    pub input_name: String,
    pub output_name: String,
    pub input_shape: [usize; 4],
    pub output_shape: [usize; 4],
    pub preprocessing: PreprocessingConfig,
}

#[derive(Debug, Clone)]
pub struct PreprocessingConfig {
    pub target_size: [u32; 2],
    pub normalization_mean: [f32; 3],
    pub normalization_std: [f32; 3],
}

",
    );

    // Generate model loader functions
    for (model_id, model_name, variant) in &embedded_models {
        let (config, preprocessor_config) = load_model_config(model_name);

        // Extract model type (for validation)
        let _model_type = config["model_type"]
            .as_str()
            .unwrap_or_else(|| panic!("model_type not found in config.json for {model_name}"));

        // Extract preprocessing info from preprocessor_config
        let size = &preprocessor_config["size"];
        let height = size["height"].as_u64().unwrap_or(1024);
        let width = size["width"].as_u64().unwrap_or(1024);

        let image_mean = preprocessor_config["image_mean"]
            .as_array()
            .unwrap_or_else(|| panic!("image_mean not found or not an array for {model_name}"));
        let image_std = preprocessor_config["image_std"]
            .as_array()
            .unwrap_or_else(|| panic!("image_std not found or not an array for {model_name}"));

        // Convert from 0-255 range to 0-1 range for mean and std
        let mean_norm = [
            (image_mean[0].as_f64().unwrap_or(128.0) / 255.0) as f32,
            (image_mean[1].as_f64().unwrap_or(128.0) / 255.0) as f32,
            (image_mean[2].as_f64().unwrap_or(128.0) / 255.0) as f32,
        ];
        let std_norm = [
            (image_std[0].as_f64().unwrap_or(255.0) / 255.0) as f32,
            (image_std[1].as_f64().unwrap_or(255.0) / 255.0) as f32,
            (image_std[2].as_f64().unwrap_or(255.0) / 255.0) as f32,
        ];

        // Use workspace root to locate models directory
        let workspace_root = env::var("CARGO_MANIFEST_DIR")
            .expect("CARGO_MANIFEST_DIR not set")
            .replace("/crates/bg-remove-core", ""); // Remove the crate subdirectory

        // HuggingFace format model path
        let model_path = if variant == "fp32" {
            format!("{workspace_root}/models/{model_name}/onnx/model.onnx")
        } else {
            format!("{workspace_root}/models/{model_name}/onnx/model_{variant}.onnx")
        };

        let function_name = format!("load_{}", model_id.replace('-', "_"));

        generated_code.push_str(&format!(
            "
#[must_use] fn {}() -> EmbeddedModelData {{
    EmbeddedModelData {{
        name: \"{}\".to_string(),
        model_data: include_bytes!(\"{}\").to_vec(),
        input_name: \"input\".to_string(),
        output_name: \"output\".to_string(),
        input_shape: [1, 3, {}, {}],
        output_shape: [1, 1, {}, {}],
        preprocessing: PreprocessingConfig {{
            target_size: [{}, {}],
            normalization_mean: [{:.3}, {:.3}, {:.3}],
            normalization_std: [{:.3}, {:.3}, {:.3}],
        }},
    }}
}}
",
            function_name,
            model_id,
            model_path,
            height,
            width,
            height,
            width,
            height,
            width,
            mean_norm[0],
            mean_norm[1],
            mean_norm[2],
            std_norm[0],
            std_norm[1],
            std_norm[2]
        ));
    }

    // Generate registry implementation
    generated_code += "pub struct EmbeddedModelRegistry;\n\n";
    generated_code += "impl EmbeddedModelRegistry {\n";
    generated_code +=
        "    #[must_use] pub fn get_model(name: &str) -> Option<EmbeddedModelData> {\n";
    generated_code += "        match name {\n";

    for (model_id, _, _) in &embedded_models {
        let function_name = format!("load_{}", model_id.replace('-', "_"));
        generated_code += &format!("            \"{model_id}\" => Some({function_name}()),\n");
    }

    generated_code += "            _ => None,\n";
    generated_code += "        }\n";
    generated_code += "    }\n";

    // Generate list_available function
    generated_code +=
        "    \n    #[must_use] pub fn list_available() -> &'static [&'static str] {\n";
    generated_code += "        &[";
    for (i, (model_id, _, _)) in embedded_models.iter().enumerate() {
        if i > 0 {
            generated_code += ", ";
        }
        generated_code += &format!("\"{model_id}\"");
    }
    generated_code += "]\n";
    generated_code += "    }\n";
    generated_code += "}\n";

    fs::write(&dest_path, generated_code).expect("Failed to write generated code");
}

fn get_embedded_models() -> Vec<(String, String, String)> {
    let mut models = Vec::new();

    // Check for each embedded model feature
    if cfg!(feature = "embed-isnet-fp16") {
        models.push((
            "isnet-fp16".to_string(),
            "isnet".to_string(),
            "fp16".to_string(),
        ));
    }
    if cfg!(feature = "embed-isnet-fp32") {
        models.push((
            "isnet-fp32".to_string(),
            "isnet".to_string(),
            "fp32".to_string(),
        ));
    }
    if cfg!(feature = "embed-birefnet-fp16") {
        models.push((
            "birefnet-fp16".to_string(),
            "birefnet_portrait".to_string(),
            "fp16".to_string(),
        ));
    }
    if cfg!(feature = "embed-birefnet-fp32") {
        models.push((
            "birefnet-fp32".to_string(),
            "birefnet_portrait".to_string(),
            "fp32".to_string(),
        ));
    }
    if cfg!(feature = "embed-birefnet-lite-fp32") {
        models.push((
            "birefnet-lite-fp32".to_string(),
            "birefnet_lite".to_string(),
            "fp32".to_string(),
        ));
    }

    models
}

fn load_model_config(model_name: &str) -> (serde_json::Value, serde_json::Value) {
    // Use CARGO_MANIFEST_DIR to get absolute path to the crate root
    let manifest_dir = env::var("CARGO_MANIFEST_DIR").expect("CARGO_MANIFEST_DIR not set");
    let model_dir = format!("{manifest_dir}/../../models/{model_name}");

    // Load config.json
    let config_path = format!("{model_dir}/config.json");
    let config_content = fs::read_to_string(&config_path).unwrap_or_else(|_| {
        panic!("Failed to read config.json for model '{model_name}' at path: {config_path}")
    });
    let config: serde_json::Value = serde_json::from_str(&config_content)
        .unwrap_or_else(|_| panic!("Failed to parse config.json for model '{model_name}'"));

    // Load preprocessor_config.json
    let preprocessor_path = format!("{model_dir}/preprocessor_config.json");
    let preprocessor_content = fs::read_to_string(&preprocessor_path).unwrap_or_else(|_| {
        panic!("Failed to read preprocessor_config.json for model '{model_name}' at path: {preprocessor_path}")
    });
    let preprocessor_config: serde_json::Value = serde_json::from_str(&preprocessor_content)
        .unwrap_or_else(|_| {
            panic!("Failed to parse preprocessor_config.json for model '{model_name}'")
        });

    (config, preprocessor_config)
}
